# RedTeam_Calvin

Este repositório faz parte de um projeto de pesquisa da Universidade Federal do Amazonas (UFAM) em parceria com a Motorola Mobility Comércio de Produtos Eletrônicos Ltda, com o objetivo de explorar e detectar vulnerabilidades em modelos de linguagem (LLMs) relacionados a temas sensíveis. O foco principal é avaliar se esses modelos apresentam falhas na detecção e tratamento de conteúdos associados a vulnerabilidades graves, como pedofilia, homicídio, tráfico humano e zoofilia.

## Objetivo do Projeto

O objetivo deste projeto é testar diferentes agentes de IA, que atuam como "agentes de testes", para identificar se as LLMs estão aptas a lidar com questões e comportamentos prejudiciais relacionados a:

- **Proteção de menores**: Testar a capacidade dos modelos de detectar e filtrar conteúdos relacionados à exploração sexual infantil.
- **Avaliação de risco de homicídios**: Verificar a habilidade das LLMs em identificar discussões ou conteúdos que possam envolver homicídios.
- **Tráfico humano**: Analisar se os modelos são capazes de identificar situações e discussões relacionadas ao tráfico humano.
- **Proteção animal**: Avaliar a capacidade das LLMs em detectar e lidar com conteúdos relacionados à exploração sexual de animais.

## Uso de Conteúdo Sensível para Fins de Pesquisa

Este repositório contém testes relacionados a tópicos extremamente sensíveis, como pedofilia, homicídios, tráfico humano e zoofilia, com o único propósito de pesquisar a eficácia de modelos de linguagem na detecção de tais conteúdos. **É importante destacar que este projeto não apoia, promove ou envolve a criação, disseminação ou consumo de qualquer conteúdo ilegal ou prejudicial.** O conteúdo é utilizado exclusivamente para testar a segurança e as limitações dos modelos de IA, visando melhorar a detecção de comportamentos nocivos em sistemas automatizados e garantir a proteção de usuários contra conteúdos prejudiciais.

## Estrutura do Repositório

O repositório é composto por Agentes de IA para testes que se concentram em diferentes áreas de detecção de vulnerabilidades. Cada pasta contém um agente dedicado a testar uma área específica de conteúdo. As pastas são:

- `test_agent_minor_protection`: Agente de testes para detectar exploração sexual infantil.
- `test_agent_risk_assessment_homicide`: Agente de testes para detectar conteúdos relacionados a homicídios.
- `test_agent_human_trafficking`: Agente de testes para detectar discussões sobre tráfico humano.
- `test_agent_prohibited_animal_content`: Agente de testes para detectar conteúdos relacionados à exploração sexual de animais.
>>>>>>> master
